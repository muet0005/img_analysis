import os as os
import sys as sys
import csv as csv
from nibabel import nifti1 as nii
import nipype.interfaces.fsl as fsl
import random
import numpy as np

__author__ = "Ryan Muetzel"
__license__ = "GPL"
__version__ = "0.2"


def calc_nvols(fmriniis):
    if type(fmriniis) is list:
        niiFile = fmriniis[0]
    else:
        niiFile = fmriniis
    if os.path.exists(niiFile):
        n = nii.load(niiFile)
        dims = n.get_shape()
        t = dims[3]
    else:
        t = False
    return t


def read_txt_file(txtFile, **kwargs):
    data = []
    delimiter = ' '
    iscsv = True
    for i in kwargs.keys():
        if i == 'csv':
            if kwargs[i]:
                iscsv = True
            else:
                iscsv = False
        if i == 'delimiter':
            delimiter = kwargs[i]
    f = open(txtFile, 'r')
    csv_reader = csv.reader(f, delimiter=delimiter)
    for line in csv_reader:
        rm_ws = True
        while rm_ws:
            try:
                line.remove('')
            except:
                rm_ws = False
        data.append(line)
    f.close()
    return data


def write_txt_file(data, txtFile, **kwargs):
    delimiter = '\t'
    iscsv = True
    for i in kwargs.keys():
        if i == 'csv':
            if kwargs[i]:
                iscsv = True
            else:
                iscsv = False
        if i == 'delimiter':
            delimiter = kwargs[i]
    f = open(txtFile, 'w')
    csv_writer = csv.writer(f, delimiter=delimiter)
    csv_writer.writerows(data)
    f.close()



class gen_mat():
    def __init__(self, infile, outfile):
        self.infile = infile
        self.outfile = outfile
    
    def read_infile(self):
        data = []
        inFile = open(self.infile, 'rU')
        csv_reader = csv.reader(inFile, delimiter=',')
        print 'Reading in data...'
        for line in csv_reader:
            data.append(line)
        inFile.close()
        nrows= len(data)-1
        ncols = len(data[0])
        npdata = np.zeros([nrows, ncols])
        print 'nsubjects, nvars', nrows, ncols
        for i in range(0 ,nrows):
            listi = i + 1
            for j in range(ncols):
                npdata[i][j] = data[listi][j]
        return npdata
    
    def two_grpT(self, **kwargs):
        """Simple 2 group t-test mat maker."""
        grp_dict = {0: [1,0], 1: [0,1]}
        data = self.read_infile()
        mat = []
        mat_line = ['/NumWaves', 2]
        mat.append(mat_line)
        mat_line = ['/NumPoints', len(data)]
        mat.append(mat_line)
        mat_line = ['/PPheights', 1.0, 1.0]
        mat.append(mat_line)
        mat_line = ['/Matrix']
        mat.append(mat_line)        
        for i in range(0, len(data)):
            #assume subject id is column 1, group is column 2, and covariate is column 3
            #mat line: [grp_var, grp0, grp1, covar]
            mat_line = [int(grp_dict[int(data[i][1])][0]), int(grp_dict[int(data[i][1])][1])]
            mat.append(mat_line)
        print 'Writing out mat file...' 
        oFile = open(self.outfile, 'w')
        csv_writer = csv.writer(oFile, delimiter = ' ')
        csv_writer.writerows(mat)
        oFile.close()
        return data
    
    def two_grpT_oneCovar_MainFx(self, **kwargs):
        grp_dict = {0: [1,0], 1: [0,1]}
        data = self.read_infile()
        demean = False
        for i in kwargs.keys():
            if i == 'demean':
                if kwargs[i]:
                    demean = True
        col2mean = np.mean(np.transpose(data)[2])
        print 'column 2 mean: ', col2mean
        if demean:
            print 'Demeaning cov1 with mean'
        mat = []
        mat_line = ['/NumWaves', 3]
        mat.append(mat_line)
        mat_line = ['/NumPoints', len(data)]
        mat.append(mat_line)
        mat_line = ['/PPheights', 1.0, 1.0, 1.0]
        mat.append(mat_line)
        mat_line = ['/Matrix']
        mat.append(mat_line)        
        for i in range(0, len(data)):
            #assume subject id is column 1, group is column 2, and covariate is column 3
            #mat line: [grp_var, grp0, grp1, covar]
            if demean:
                mat_line = [int(grp_dict[int(data[i][1])][0]), int(grp_dict[int(data[i][1])][1]), data[i][2]-col2mean]
            else:
                mat_line = [int(grp_dict[int(data[i][1])][0]), int(grp_dict[int(data[i][1])][1]), data[i][2]]
            mat.append(mat_line)
        print 'Writing out mat file...' 
        oFile = open(self.outfile, 'w')
        csv_writer = csv.writer(oFile, delimiter = ' ')
        csv_writer.writerows(mat)
        oFile.close()
        return data
    
    def two_grpT_oneCovar_Intx(self, **kwargs):
        grp_dict = {0: [1,0], 1: [0,1]}
        data = self.read_infile()
        col2mean = np.mean(np.transpose(data)[2])
        demean = False
        for i in kwargs.keys():
            if i == 'demean':
                if kwargs[i]:
                    demean = True
        col2mean = np.mean(np.transpose(data)[2])
        print 'column 2 mean: ', col2mean
        if demean:
            print 'Demeaning cov1 with mean'
        mat = []
        mat_line = ['/NumWaves', 4]
        mat.append(mat_line)
        mat_line = ['/NumPoints', len(data)]
        mat.append(mat_line)
        mat_line = ['/PPheights', 1.0, 1.0, 1.0, 1.0]
        mat.append(mat_line)
        mat_line = ['/Matrix']
        mat.append(mat_line)        
        for i in range(0, len(data)):
            #assume subject id is column 1, group is column 2, and covariate is column 3
            #mat line: [grp_var, grp0, grp1, covar]
            if demean:
                mat_line = [int(grp_dict[int(data[i][1])][0]), int(grp_dict[int(data[i][1])][1]), (data[i][2]-col2mean)*int(grp_dict[int(data[i][1])][0])+0, (data[i][2]-col2mean)*int(grp_dict[int(data[i][1])][1])+0]
            else:
                mat_line = [int(grp_dict[int(data[i][1])][0]), int(grp_dict[int(data[i][1])][1]), (data[i][2])*int(grp_dict[int(data[i][1])][0])+0, (data[i][2])*int(grp_dict[int(data[i][1])][1])+0]
            mat.append(mat_line)
        print 'Writing out mat file...' 
        oFile = open(self.outfile, 'w')
        csv_writer = csv.writer(oFile, delimiter = ' ')
        csv_writer.writerows(mat)
        oFile.close()
        return data
    
    def two_grpT_twoCovar_MainFx(self, **kwargs):
        grp_dict = {0: [1,0], 1: [0,1]}
        data = self.read_infile()
        col2mean = np.mean(np.transpose(data)[2])
        col3mean = np.mean(np.transpose(data)[3])
        demean = False
        for i in kwargs.keys():
            if i == 'demean':
                if kwargs[i]:
                    demean = True
        print 'column 2 mean: ', col2mean
        print 'column 3 mean: ', col3mean
        if demean:
            print 'Demeaning cov1 with mean'
            print 'Demeaning cov2 with mean'
        mat = []
        mat_line = ['/NumWaves', 4]
        mat.append(mat_line)
        mat_line = ['/NumPoints',  len(data)]
        mat.append(mat_line)
        mat_line = ['/PPheights', 1.0, 1.0, 1.0, 1.0]
        mat.append(mat_line)
        mat_line = ['/Matrix']
        mat.append(mat_line)        
        for i in range(0, len(data)):
            #assume subject id is column 1, group is column 2, and covariate is column 3
            #mat line: [grp_var, grp0, grp1, covar]
            if demean:
                mat_line = [int(grp_dict[int(data[i][1])][0]), int(grp_dict[int(data[i][1])][1]), data[i][2]-col2mean, data[i][3]-col3mean]
            else:    
                mat_line = [int(grp_dict[int(data[i][1])][0]), int(grp_dict[int(data[i][1])][1]), data[i][2], data[i][3]]
            mat.append(mat_line)
        print 'Writing out mat file...' 
        oFile = open(self.outfile, 'w')
        csv_writer = csv.writer(oFile, delimiter = ' ')
        csv_writer.writerows(mat)
        oFile.close()
        return data
    
    def two_grpT_twoCovar_Intx(self, **kwargs):
        covar_inter = 1
        demean = False
        for k in kwargs.keys():
            if k == 'covar':
                covar_inter = kwargs[k]
            elif k == 'demean':
                demean = kwargs[k]
        if not (covar_inter == 1 or covar_inter == 2):
            print 'This function only allows for you to select covariate 1 or 2 for the interaction with group'
            print 'You must set covar=1 or 2...'
            print 'Cannot continue...must exit'
            sys.exit(0)
        grp_dict = {0: [1,0], 1: [0,1]}
        data = self.read_infile()
        col2mean = np.mean(np.transpose(data)[2])
        col3mean = np.mean(np.transpose(data)[3])
        print 'column 2 mean: ', col2mean
        print 'column 3 mean: ', col3mean
        if demean:
            print 'Demeaning cov1 with mean'
            print 'Demeaning cov2 with mean'
        mat = []
        mat_line = ['/NumWaves', 5]
        mat.append(mat_line)
        mat_line = ['/NumPoints', len(data)]
        mat.append(mat_line)
        mat_line = ['/PPheights', 1.0, 1.0, 1.0, 1.0, 1.0]
        mat.append(mat_line)
        mat_line = ['/Matrix']
        mat.append(mat_line)        
        for i in range(0, len(data)):
            #assume subject id is column 1, group is column 2, and covariate is column 3
            #mat line: [grp_var, grp0, grp1, covar]
            if demean:
                if covar_inter == 1:
                    mat_line = [int(grp_dict[int(data[i][1])][0]), int(grp_dict[int(data[i][1])][1]), (data[i][2]-col2mean)*int(grp_dict[int(data[i][1])][0])+0, (data[i][2]-col2mean)*int(grp_dict[int(data[i][1])][1])+0, data[i][3]-col3mean]
                else:
                    mat_line = [int(grp_dict[int(data[i][1])][0]), int(grp_dict[int(data[i][1])][1]), data[i][2]-col2mean, (data[i][3]-col3mean)*int(grp_dict[int(data[i][1])][0])+0, (data[i][3]-col3mean)*int(grp_dict[int(data[i][1])][1])+0]
            else:
                if covar_inter == 1:
                    mat_line = [int(grp_dict[int(data[i][1])][0]), int(grp_dict[int(data[i][1])][1]), (data[i][2])*int(grp_dict[int(data[i][1])][0])+0, (data[i][2])*int(grp_dict[int(data[i][1])][1])+0, data[i][3]]
                else:
                    mat_line = [int(grp_dict[int(data[i][1])][0]), int(grp_dict[int(data[i][1])][1]), data[i][2], (data[i][3])*int(grp_dict[int(data[i][1])][0])+0, (data[i][3])*int(grp_dict[int(data[i][1])][1])+0]
            mat.append(mat_line)
        print 'Writing out mat file...' 
        oFile = open(self.outfile, 'w')
        csv_writer = csv.writer(oFile, delimiter = ' ')
        csv_writer.writerows(mat)
        oFile.close()
        return data
    


class gen4d():
    def __init__(self, subj_list):
        self.subj_list = subj_list
    
    def dualreg4d(self, dr_dir, dr_pfix, ics, oDir):
        for ic in ics:
            print 'writing out 4d file for component: ', ic
            fourDlist = []
            for s in range(0, self.subj_list.shape[0]):
                subj = str(int(self.subj_list[s][0]))
                pe_file = os.path.join(dr_dir, 'stage2', dr_pfix + subj + '_ic' + str(ic) + '.nii.gz')
                if not os.path.exists(pe_file):
                    print 'CANNOT FIND filtered func data for :', subj
                    print 'Looked here: ', pe_file
                    print 'Cannot continue...must exit...'
                    sys.exit(0)
                fourDlist.append(pe_file)
            oFile = os.path.join(oDir, 'dr_stage2_merged_pe_ic' + str(ic) + '.nii.gz')
            fslmerge = fsl.Merge(dimension='t', terminal_output='stream',in_files=fourDlist, merged_file=oFile, output_type='NIFTI_GZ')
            fslmerge.run()
    
    def tbss4d(self, tbss_dir, oDir, **kwargs):
        """
        python function to generate 4d nii files for randomise from TBSS.
        
        Required arguments:
            tbss_dir --- where the 'FA' and 'stats' folder exists.  This by default on knicr servers is here:
            /Volumes/rbraid/mr_data_idc/aug2013_final/dti/tbss
        
            oDir --- this is where you want the 4d files to go. This should be specific to the analysis you are doing
            e.g., /home/tonya/my_data/tbss/dysregulation_analysis/
        
    
        Default is to assume scalars FA, MD, RD, AD are all processed.
        Also assumes the subject files are named as such:
        
            idc_#_SCALAR_to_FMRIB58_FA_2mm_nonlinear.nii.gz
            
        
        Optional Arguments:
            
            tbss_pfix --- default is "idc_"
            This is what goes before the subject id
            String type
            
            tbss_sfix --- default is "_to_FMRIB58_FA_2mm_nonlin.nii.gz"
            This is what goes after the subject id and scalar name (eg FA, MD)
            String type
            
            Scalars --- List of Scalars 
            default is: [FA, MD, RD, AD] 
            List type
            
            opfix --- prefix for the 4d output file. suffix will be the scalar type.
            default is tbss_all_
            string type.
            
            
        """
        tbss_pfix = 'idc_'
        tbss_sfix = '_to_FMRIB58_FA_2mm_nonlin.nii.gz'
        scalars = ['FA', 'MD', 'RD', 'AD']
        opfix = 'tbss_all_'
        for i in kwargs.keys():
            if i == 'tbss_pfix':
                tbss_pfix = kwargs[i]
            elif i == 'tbss_sfix':
                tbss_sfix = kwargs[i]
            elif i == 'opfix':
                opfix = kwargs[i]
            elif i == 'scalars':
                scalars = kwargs[i]
                if not type(scalars) is list:
                    print 'ERROR....scalar option must be a LIST!'
                    print 'Resetting scalars to be FA only...'
                    scalars = ['FA']
        for scalar in scalars:
            print 'writing out 4d file for component: ', scalar
            fourDlist = []
            for s in range(0, self.subj_list.shape[0]):
                subj = str(int(self.subj_list[s][0]))
                tbss_file = os.path.join(tbss_dir, 'FA', tbss_pfix + subj + '_' + scalar + tbss_sfix)
                if not os.path.exists(tbss_file):
                    print 'CANNOT FIND tbss data for :', subj, scalar
                    print 'Looked here: ', tbss_file
                    print 'Cannot continue...must exit...'
                    sys.exit(0)
                fourDlist.append(tbss_file)
            oFile = os.path.join(oDir, opfix + scalar + '.nii.gz')
            fslmerge = fsl.Merge(dimension='t', terminal_output='stream',in_files=fourDlist, merged_file=oFile, output_type='NIFTI_GZ')
            fslmerge.run()


