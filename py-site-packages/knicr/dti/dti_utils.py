import os as os
import sys as sys
import csv as csv
import numpy as np
import shutil as shutil
import nibabel as nb
from nibabel import nifti1 as nii
import nipype.interfaces.fsl as fsl
import nipype.interfaces.freesurfer as freesurfer
from nipype.interfaces.base import Undefined
import subprocess as sp
import socket as socket
import datetime as datetime
import argparse as argparse


__author__ = "Ryan Muetzel"
__license__ = "GPL"
__version__ = "0.2"



def write_log(cmd, oFile):
    """
    write_log
    Simple function to track data provenance via the nipype package
    
    Arguments:
    cmd: usually the nipype function.cmdline
    
    oFile: the file you want to write the logging to.
    """
    if os.path.exists(oFile):
        f = open(oFile, 'a')
    else:
        f = open(oFile, 'w')
    f.write('#######--------NEW INSTANCE CALLED--------#######' + '\n')
    f.write('timestamp=' + datetime.datetime.now().strftime('%d%b%Y_%H:%M:%S') + '\n')
    f.write('user=' + os.getlogin() + '\n')
    f.write('pwd=' + os.getcwd() + '\n')
    f.write('domainname=' + socket.getfqdn() + '\n')
    f.write('hostname=' + socket.gethostname() + '\n')
    f.write('osUname=' + str(os.uname()) + '\n')
    f.write('PythonVersion=' + sys.version + '\n')
    f.write(cmd + '\n')
    f.write('#######--------END OF LOG--------#######' + '\n')
    f.close()


def read_txt(txtFile):
    t = open(txtFile, 'r')
    raw_data = [] ; data = []
    csv_reader = csv.reader(t, delimiter=',')
    for line in csv_reader:
        raw_data.append(line[0])
    num_rows = len(raw_data)
    for i in range(0, num_rows):
        if not i == 0:
            data.append(raw_data[i])
    t.close()
    return data


def write_txt(data, txtFile):
    t = open(txtFile, 'w')
    if isinstance(data[0], list):
        csv_writer = csv.writer(t, delimiter=',')
        csv_writer.writerows(data)
    else:
        for i in data:
            t.write(i + '\n')
    t.close()


def read_fs_clut():
    """
    returns dictionary of freesurfer color lookup table
    
    key = index
    value = ROI
    """
    fslut = open(os.path.join(os.environ['FREESURFER_HOME'], 'FreeSurferColorLUT.txt'), 'r')
    fslut_csv = csv.reader(fslut, delimiter=' ')
    fs_clut = {}
    print 'Reading FS color lookup table...',
    for line in fslut_csv:
        if len(line) == 0:
            continue
        elif line[0].startswith('#'):
            continue
        replace_ws = True
        while replace_ws:
            try:
                line.remove('')
            except:
                replace_ws = False
        roi = line[1] ; index = line[0]
        fs_clut[index] = roi
    print 'Loaded: ', len(fs_clut), ' FreeSurfer Labels.'
    fslut.close()
    return fs_clut


def compute_Waverage(iFile, mask, **kwargs):
    """
    Compute a weighted average of a mask
    
    Two inputs:
    iFile = input file that is to be average
    
    mask = area of input file included in average
    
    optional args:
    
    rescale = bool. True means the mask will be rescaled to be 0->1.
    """
    rescale = False
    for i in kwargs.keys():
        if i == 'rescale':
            rescale = kwargs[i]
    iData = nb.load(iFile).get_data()
    mask_data = nb.load(mask).get_data()
    if rescale:
        if np.max(mask_data) > 0:
            mask_data = mask_data / np.max(mask_data)
        else:
            print 'WARNING: Cannot rescale mask image...'
    wavg = np.average(iData, weights=mask_data)
    return wavg


class knicrDTIprep():
    def __init__(self, dtiDir, subject):
        """
        Class to preprocess KNICR MRI data using FSL tools
        
        bet:  Brain Extraction Tool.
        
        ecc: Eddy Current Correction (eddy_correct)
        
        rot_bvecs:  xfmrot from FreeSurfer to rotate the gradient table based on the ecc.log
        
        fit: dtifit to fit the diffusion tensor
        
        Initialization arguments:
            dtiDir: Where the dti images reside
                    Assumes the dwi is called: dti_idc_${subject}_2mm.nii.gz
            
            subject: the Subject ID 
        """
        self.subjDir = os.path.join(dtiDir, subject)
        self.dtifitDir = os.path.join(self.subjDir, 'dmri')
        self.subject = subject
        if not os.path.exists(self.dtifitDir):
            os.makedirs(self.dtifitDir)
        self.dwi = os.path.join(self.subjDir, 'dti_idc_' + str(subject) + '_2mm.nii.gz')
        self.data = os.path.join(self.dtifitDir, 'data.nii.gz')
        self.bvecs = os.path.join(self.dtifitDir, 'bvecs.ecc')
        self.bvals = os.path.join(self.dtifitDir, 'bvals')
        self.nodif_brain_mask = os.path.join(self.dtifitDir, 'nodif_brain_mask.nii.gz')
    
    def bet(self, **kwargs):
        #a default of 0.25 seems to work well
        f = 0.25
        #ability to overwrite with this
        for i in kwargs.keys():
            if i == 'f':
                f = kwargs[i]
        #check to see if the mask needs to be created.
        if not os.path.exists(self.nodif_brain_mask):
            print 'Running BET on: ', self.dwi
            nodif_brain = self.nodif_brain_mask.replace('_mask.nii.gz', '.nii.gz')
            bet = fsl.BET(frac=f, in_file=self.dwi, mask=True, out_file=nodif_brain)
            bet.run()
            logFile = os.path.join(self.dtifitDir, 'bet.log')
            write_log(bet.cmdline, logFile)
    
    def ecc(self):
        if not os.path.exists(self.data):
            print 'Running eddy_correct on:', self.dwi
            eddy_correct = fsl.EddyCorrect(in_file=self.dwi, out_file=self.data, ref_num=0, terminal_output='stream', ignore_exception=True)
            eddy_correct.run()
            logFile = os.path.join(self.dtifitDir, 'eddy_correct.log')
            write_log(eddy_correct.cmdline, logFile)
    
    def rot_bvecs(self):
        #rotate the bvecs based on the ECC output.    
        #xfmrot ecclog in_bvecs out_bvecs
        eccmat = os.path.join(self.dtifitDir, 'data.ecclog')
        if not os.path.exists(self.bvecs):
            print 'Rotating gradient table for eddy current correction: ', self.bvecs
            bvec_raw = os.path.join(self.subjDir, 'dti_idc_' + str(self.subject) + '.bvec')
            shutil.copyfile(bvec_raw.replace('.bvec', '.bval'), self.bvals)
            sp.call(["xfmrot", eccmat, bvec_raw, self.bvecs])
    
    def fit(self):
        obn = os.path.join(self.dtifitDir, 'dtifit')
        fa = obn + '_FA.nii.gz'
        if not os.path.exists(fa):
            print 'Fitting the tensor: ', fa
            #in the current version of nipype...it doesn't handle the out_files properly, in terms of finding them
            #thus, the ignore_exception flag is activated..
            dtifit = fsl.DTIFit(base_name=obn, bvals=self.bvals, bvecs=self.bvecs, dwi=self.data, mask=self.nodif_brain_mask, terminal_output='stream', ignore_exception=True)
            dtifit.run()
            logFile = obn + '.log'
            write_log(dtifit.cmdline, logFile)
            #Next make the axial diffusion scan...a simple copy of the primary eigen value
            iFile = obn + '_L1.nii.gz'
            oFile = obn + '_AD.nii.gz'
            fslmaths = fsl.ImageMaths(in_file=iFile, out_file=oFile, output_type='NIFTI_GZ', out_data_type='float')
            fslmaths.run()
            logFile = obn + '.log'
            write_log(fslmaths.cmdline, logFile)
            #next make the radial diffusivity scan...an average of the secondary and tertiary eigenvalues
            iFile = obn + '_L2.nii.gz'
            rd_op_str = '-add ' + obn + '_L3.nii.gz' + ' -div 2'
            oFile = obn + '_RD.nii.gz'
            fslmaths = fsl.ImageMaths(in_file=iFile, op_string=rd_op_str, out_file=oFile, output_type='NIFTI_GZ', out_data_type='float')
            fslmaths.run()
            logFile = obn + '.log'
            write_log(fslmaths.cmdline, logFile)
    
    def bedpost(self):
        bpxDir = self.dtifitDir + '.bedpostX'
        nfibers=2
        logFile = os.path.join(self.dtifitDir, 'bedpostX.log')
        #the rotated bvecs has '.ecc' appened...copy this to be bvecs for bedpost
        shutil.copyfile(self.bvecs, self.bvecs.replace('.ecc', ''))
        if not os.path.exists(bpxDir):
            bpx = fsl.BEDPOSTX(dwi=self.data, bvecs=self.bvecs, bvals=self.bvals, mask=self.nodif_brain_mask, fibres=nfibers, bpx_directory=self.dtifitDir)
            bpx.run()
            write_log(bpx.cmdline, logFile)
    


class knicrDTIreg():
    def __init__(self, dtiDir, subject):
        self.subjDir = os.path.join(dtiDir, subject, 'dmri')
        self.regDir = os.path.join(dtiDir, subject, 'reg')
        self.labelDir = os.path.join(dtiDir, subject, 'label')
        self.subject = subject
        if not os.path.exists(self.subjDir):
            print 'dmri folder not present: ', self.subjDir
            print 'Please run knicrDTIpp FIRST!'
            sys.exit(0)
        if not os.path.exists(self.regDir):
            os.makedirs(self.regDir)
        if not os.path.exists(self.labelDir):
            os.makedirs(self.labelDir)
    
    def fsreg(self, subjects_dir):
        """
        fsreg:  Tool to align the dwi data to the FreeSurfer brain.mgz using FNIRT
        
        Prereq:  knicrDTIprep is run first and autorecon-all is run on the T1.
        
        Step 1: 6dof flirt dwi -> brain.mgz
        Step 2: FNIRT dwi -> brain.mgz
        Step 3: invert warp from step 2
        """
        #take the FA map (requires knicrDTIprep is run)
        fa = os.path.join(self.subjDir, 'dtifit_FA.nii.gz')
        #where the brain.mgz will be found later
        fsdir = os.path.join(subjects_dir, self.subject)
        #data prov. 
        logFile = os.path.join(self.regDir, 'fsreg.log')
        #make sure they have a freesurfer dataset
        if not os.path.exists(fsdir):
            print 'Cannot find subjects dir: ', fsdir
            return False
        #first convert brain.mgz -> brain.nii.gz for FSL
        iFile = os.path.join(fsdir, 'mri', 'brain.mgz')
        anat = os.path.join(self.regDir, 'fsbrain.nii.gz')
        if not os.path.exists(iFile):
            print 'Subject does not have brain.mgz', iFile
            return False
        if not os.path.exists(anat):
            mri_convert = freesurfer.MRIConvert(in_file=iFile, out_file=anat)
            mri_convert.run()
            write_log(mri_convert.cmdline, logFile)
        #because the BET isn't perfect on the FA map, we have a bright ring around the brain
        #do a few erosions to get rid of it, as it messes up the FNIRT
        fa_ero = os.path.join(self.regDir, 'dtifit_FA_ero.nii.gz')
        if not os.path.exists(fa_ero):
            fslmaths = fsl.ImageMaths(in_file=fa, op_string='-ero -ero', out_file=fa_ero, output_type='NIFTI_GZ', out_data_type='float')
            fslmaths.run()
            write_log(fslmaths.cmdline, logFile)
        ##do we need to do the "flip for fsl" crap?
        #next do the flirt, FA -> brain.nii.gz
        oFile = os.path.join(self.regDir, os.path.basename(fa_ero).replace('.nii.gz', '_to_fsbrain_lin.nii.gz'))
        mat = os.path.join(self.regDir, os.path.basename(fa_ero).replace('.nii.gz', '_to_fsbrain_lin.mat'))
        if not os.path.exists(oFile):
            print 'Registering FA to fs anatomical using FLIRT.'
            search = [-180, 180]
            flirt = fsl.FLIRT(in_file=fa_ero, reference=anat, out_file=oFile, out_matrix_file=mat, dof=6, searchr_x=search, searchr_y=search, searchr_z=search)
            flirt.run()
            write_log(flirt.cmdline, logFile)
        #next do the FNIRT, FA -> brain.nii.gz
        oFile = os.path.join(self.regDir, os.path.basename(fa_ero).replace('.nii.gz', '_to_fsbrain_nonlin.nii.gz'))
        log = oFile.replace('.nii.gz', '_log.txt')
        warp = oFile.replace('.nii.gz', '_warp.nii.gz')
        config='FA_2_FMRIB58_1mm'
        if not os.path.exists(warp):
            print 'Registering FA to fs anatomical using FNIRT.'
            fnirt = fsl.FNIRT(in_file=fa_ero, fieldcoeff_file=warp, warped_file=oFile, affine_file=mat, config_file=config, ref_file=anat, log_file=log)
            fnirt.run()
            write_log(fnirt.cmdline, logFile)
        #next do the invwarp to the warp file
        oFile = os.path.join(self.regDir, 'fsbrain_to_' + os.path.basename(fa_ero).replace('.nii.gz', '_nonlin.nii.gz'))    
        inverted_warp = oFile.replace('.nii.gz', '_warp.nii.gz')
        if not os.path.exists(inverted_warp):
            ##there is an error in the nipype.interfaces.fsl.utils file....the inverse_warp input spec is set to True, and should not be.
            print 'Inverting nonlinear warp.'
            invwarp = fsl.InvWarp(reference=fa_ero, warp=warp, inverse_warp=inverted_warp)
            invwarp.run()
            write_log(invwarp.cmdline, logFile)
        #last but not least, apply the warp to the T1, so we have a t1 image in dti space (to make sure the reg worked)
        if not os.path.exists(oFile):
            applywarp = fsl.ApplyWarp(in_file=anat, field_file=inverted_warp, out_file=oFile, ref_file=fa_ero, relwarp=True)
            applywarp.run()
            write_log(applywarp.cmdline, logFile)
    
    def mapFSLabel2Diff(self, subjects_dir, **kwargs):
        """
        Map freesurfer labels to diffusion data.
        
        ***Assumes the fs_reg function has been run!
        
        Will map the wmparc, aparc and aseg labels by default.
        
        Ranges are set for indices within the freesurfer color lut. 
        
        todo: Eventually build in kwargs for the following:
            indice ranges for wmparc, aparc and aseg, to specify a sub-set of labes.
            by default, it ignores the a2009s labels
            perhaps add support for other segmentations (i.e., ba labels)
        """
        #specify the warp transform from anat->diff (from fs_reg)
        warp = os.path.join(self.regDir, 'fsbrain_to_dtifit_FA_ero_nonlin_warp.nii.gz')
        #point to the fa map (only for output resolution / dims)
        fa = os.path.join(self.regDir, 'dtifit_FA_ero.nii.gz')
        #do you want to ignore the -G and -S (gyral and sulcal labels...probably yes)
        ignore_a2009s = True
        sw = ('ctx-lh-S', 'ctx-lh-G','ctx-rh-S', 'ctx-rh-G', 'wm-lh-S', 'wm-lh-G', 'wm-rh-S', 'wm-rh-G')
        #which parcellations will be run
        parcTypes = ['wmparc', 'aparc', 'aseg']
        #make sure the warp is present...if not, must quit
        if not os.path.exists(warp):
            print 'Cannot find nonlinear warp file..must exit..', warp
            return False
        #these are the indice ranges from the freesurfer color lut.
        #0-80 roughly = aseg ; 1000-3000 is aparc, and 3000-5000 is wmparc
        parc_range={'wmparc':[3000, 4999], 'aparc':[1000, 2999], 'aseg':[1, 60]}
        #keep provenance info
        logFile = os.path.join(self.labelDir, 'mapFSlabel2diff.log')
        #read the color look-up-table
        fs_clut = read_fs_clut()
        #we have short names "parcTypes" for each parcellation, and these have different file names
        for parcType in parcTypes:
            print 'Mapping FreeSurfer labels to diffusion space: ', parcType,
            if parcType == 'wmparc':
                parcFile = 'wmparc'
            elif parcType == 'aparc':
                parcFile = 'aparc+aseg'
            elif parcType == 'aseg':
                parcFile = 'aparc+aseg'
            else:
                print 'Unknown parcellation...must skip'
                continue
            #make an output folder for the data ; one for the 1mm FS data, and one for the DTI data
            anatLabelDir = os.path.join(self.labelDir, parcType, 'anat')
            diffLabelDir = os.path.join(self.labelDir, parcType, 'diff')
            if not os.path.exists(anatLabelDir):
                os.makedirs(anatLabelDir)
            if not os.path.exists(diffLabelDir):
                os.makedirs(diffLabelDir)
            #The original fs parcellation file
            parc_anat = os.path.join(subjects_dir, self.subject, 'mri', parcFile + '.mgz')
            #the new one in Nifti format
            parc = os.path.join(anatLabelDir, parcFile + '.nii.gz')
            #if the nifti one isn't mde yet, use mri_convert to generate it
            if not os.path.exists(parc):
                mri_convert = freesurfer.MRIConvert(in_file=parc_anat, out_file=parc)
                mri_convert.run()
                write_log(mri_convert.cmdline, logFile)
            #now loop over the index ranges you specified above
            for index in range(parc_range[parcType][0], parc_range[parcType][1]):
                index = str(index)
                #make sure it's actually in our dictionary
                if not fs_clut.has_key(index):
                    continue
                #get the ROI
                roi = fs_clut[index]
                #ignore the gyral and sulcal labels
                if ignore_a2009s:
                    if roi.startswith(sw):
                        continue
                #make an output mask in FS space
                anat_label = os.path.join(anatLabelDir, roi + '.nii.gz')
                if not os.path.exists(anat_label):
                    print '.',
                    op_str = '-thr ' + index + ' -uthr ' + index + ' -bin'
                    fslmaths = fsl.ImageMaths(in_file=parc, op_string=op_str, out_file=anat_label, output_type='NIFTI_GZ')
                    fslmaths.run()
                    write_log(fslmaths.cmdline, logFile)
                #now warp the mask from the previous step to diffusion space
                diff_label = os.path.join(diffLabelDir, roi + '.nii.gz')
                if not os.path.exists(diff_label):
                    applywarp = fsl.ApplyWarp(in_file=anat_label, field_file=warp, out_file=diff_label, ref_file=fa, relwarp=True, interp='nn')
                    applywarp.run()
                    write_log(applywarp.cmdline, logFile)
            print 'Done.'
    
    def stSpaceReg(self, template):
        fa = os.path.join(self.subjDir, 'dmri', 'dtifit_FA.nii.gz')
        fa_ero = os.path.join(self.regDir, 'dtifit_FA_ero.nii.gz')
        logFile = os.path.join(self.regDir, os.path.basename(template).replace('.nii.gz', '_registration.log'))
        if not os.path.exists(fa_ero):
            fslmaths = fsl.ImageMaths(in_file=fa, op_string='-ero -ero', out_file=fa_ero, output_type='NIFTI_GZ', out_data_type='float')
            fslmaths.run()
            write_log(fslmaths.cmdline, logFile)
        oFile = os.path.join(self.regDir, os.path.basename(fa_ero).replace('.nii.gz', '_to_') + os.path.basename(template).replace('.nii.gz', '_lin.nii.gz'))
        mat = oFile.replace('.nii.gz', '.mat')
        if not os.path.exists(oFile):
            print 'Registering FA map to standard space with FLIRT: ', template
            search = [-180, 180]
            flirt = fsl.FLIRT(in_file=fa_ero, reference=template, out_file=oFile, out_matrix_file=mat, dof=12, searchr_x=search, searchr_y=search, searchr_z=search)
            flirt.run()
            write_log(flirt.cmdline, logFile)
        oFile = oFile.replace('_lin.nii.gz', '_nonlin.nii.gz')
        log = oFile.replace('.nii.gz', '.log')
        warp = oFile.replace('.nii.gz', '_warp.nii.gz')
        config='FA_2_FMRIB58_1mm'
        if not os.path.exists(warp):
            print 'Registering FA map to standard space with FNIRT: ', template
            fnirt = fsl.FNIRT(in_file=fa_ero, fieldcoeff_file=warp, warped_file=oFile, affine_file=mat, config_file=config, ref_file=template, log_file=log)
            fnirt.run()
            write_log(fnirt.cmdline, logFile)
        oFile = os.path.join(self.regDir, os.path.basename(template).replace('.nii.gz', '_to_') + os.path.basename(fa_ero).replace('.nii.gz', '_nonlin.nii.gz'))
        inverted_warp = oFile.replace('.nii.gz', '_warp.nii.gz')
        if not os.path.exists(inverted_warp):
            print 'Inverting nonlinear warp field.'
            invwarp = fsl.InvWarp(reference=fa_ero, warp=warp, inverse_warp=inverted_warp)
            invwarp.run()
            write_log(invwarp.cmdline, logFile)
        if not os.path.exists(oFile):
            applywarp = fsl.ApplyWarp(in_file=template, field_file=inverted_warp, out_file=oFile, ref_file=fa_ero, relwarp=True)
            applywarp.run()
            write_log(applywarp.cmdline, logFile)
    


class knicrAutoPtx():
    def __init__(self, dtiDir, subject, autoptxLib):
        self.subjDir = os.path.join(dtiDir, subject)
        self.regDir = os.path.join(self.subjDir, 'reg')
        self.autoptxDir = os.path.join(self.subjDir, 'autoptx')
        self.bpxDir = os.path.join(self.subjDir, 'dmri.bedpostX')
        self.autoptxLib = autoptxLib
        if not os.path.exists(self.bpxDir):
            return False
        if not os.path.exists(self.autoptxDir):
            os.makedirs(self.autoptxDir)
    
    def autoPtx_1_preproc(self):
        """
        Preprocess the diffusion data for automated tracking.
        
        The knicr version of this is actually done with knicrDTIprep() & knicrDTIreg()
        
        Here, we only make the 1mm native space refvol.
        """
        refvol = os.path.join(self.autoptxDir, 'refvol.nii.gz')
        if not os.path.exists(refvol):
            logFile = os.path.join(self.autoptxDir, 'autoptx_1_preproc.log')
            fa = os.path.join(self.regDir, 'dtifit_FA_ero.nii.gz')
            op_str = '-applyisoxfm 1'
            flirt = fsl.FLIRT(in_file=fa, reference=fa, out_file=refvol, args=op_str)
            flirt.run()
            write_log(flirt.cmdline, logFile)
            op_str = '-mul 0'
            fslmaths = fsl.ImageMaths(in_file=refvol, op_string=op_str, out_file=refvol, output_type='NIFTI_GZ')
            fslmaths.run()
            write_log(fslmaths.cmdline, logFile)
    
    def autoPtx_2_launchTractography(self):
        overwrite = False
        logFile = os.path.join(self.autoptxDir, 'autoptx_2_launchtractography.log')
        refvol = os.path.join(self.autoptxDir, 'refvol.nii.gz')
        def read_autoPtxStructureList():
            structureList = open(os.path.join(self.autoptxLib, 'structureList'), 'r')
            structureInfo = {}
            structureCsv = csv.reader(structureList, delimiter=' ')
            for line in structureCsv:
                rmws = True
                while rmws:
                    try:
                        line.remove('')
                    except:
                        rmws = False
                struct,factor,walltime = line
                structureInfo[struct] = factor
            structureList.close()
            return structureInfo
        
        structInfo = read_autoPtxStructureList()
        print 'Running automated tractography of subject: ', self.subjDir
        for struct in structInfo.keys():
            nSeed = 1000
            nSeed = int(nSeed * float(structInfo[struct]))
            print 'Structure: ', struct, ' using ', nSeed, ' seeds per voxel.'
            masks = os.path.join(self.autoptxLib, 'protocols', struct)
            warp = os.path.join(self.regDir, 'FMRIB58_FA_1mm_to_dtifit_FA_ero_nonlin_warp.nii.gz')
            tracts = os.path.join(self.autoptxDir, 'tracts', struct)
            invert=False
            if overwrite and os.path.exists(tracts):
                    shutil.rmtree(tracts)
            if not os.path.exists(tracts):
                os.makedirs(tracts)
                os.makedirs(os.path.join(tracts, 'tracts'))
                def warp_masks(iFile, oFile):
                    if not os.path.exists(oFile):
                        applywarp = fsl.ApplyWarp(in_file=iFile, field_file=warp, out_file=oFile, ref_file=refvol, datatype='float')
                        applywarp.run()
                        write_log(applywarp.cmdline, logFile)
                        op_str = '-thr 0.1 -bin'
                        fslmaths = fsl.ImageMaths(in_file=oFile, op_string=op_str, out_file=oFile, output_type='NIFTI_GZ', out_data_type='char')
                        fslmaths.run()
                        write_log(fslmaths.cmdline, logFile)
                
                mask_list = ['seed', 'target', 'stop', 'exclude']
                for m in mask_list:
                    if m == 'seed':
                        seed_mni = os.path.join(masks, 'seed.nii.gz')
                        seed = os.path.join(tracts, 'seed.nii.gz')
                        warp_masks(seed_mni, seed)
                    elif m == 'target':
                        target_mni = os.path.join(masks, 'target.nii.gz')
                        target = os.path.join(tracts, 'target.nii.gz')
                        warp_masks(target_mni, target)
                    elif m == 'exclude':
                        exclude_mni = os.path.join(masks, 'exclude.nii.gz')
                        exclude = os.path.join(tracts, 'exclude.nii.gz')
                        warp_masks(exclude_mni, exclude)
                    elif m == 'stop':
                        stop_mni = os.path.join(masks, 'stop.nii.gz')
                        stop = Undefined
                        if os.path.exists(stop_mni):
                            stop = os.path.join(tracts, 'stop.nii.gz')
                            warp_masks(stop_mni, stop)
                invert = False
                if os.path.exists(os.path.join(masks, 'invert')):
                    invert = True
                ptx = fsl.ProbTrackX2(seed=seed, waypoints=target, samples_base_name=os.path.join(self.bpxDir, 'merged'), 
                mask=os.path.join(self.subjDir, 'dmri', 'nodif_brain_mask.nii.gz'), stop_mask=stop, n_samples=nSeed, opd=True, 
                out_dir=os.path.join(tracts, 'tracts'), avoid_mp=exclude, loop_check=True, force_dir=True, onewaycondition=invert, terminal_output='stream')
                ptx.run()
                write_log(ptx.cmdline, logFile)
                #if invert:
                #    if not os.path.exists(os.path.join(tracts, 'tractsInv')):
                #        os.makedirs(os.path.join(tracts, 'tractsInv'))
                #    ptx = fsl.ProbTrackX(seed=target, waypoints=seed, fsamples=fsamples, phsamples=phsamples, thsamples=thsamples, samples_base_name=os.path.join(self.bpxDir, 'merged'), 
                #    mask=os.path.join(self.subjDir, 'dmri', 'nodif_brain_mask.nii.gz'), stop_mask=stop, n_samples=nSeed, opd=True, 
                #    out_dir=os.path.join(tracts, 'tractsInv'), avoid_mp=avoid, loop_check=True, force_dir=True, terminal_output='stream')
                #    ptx.run()
                #    write_log(ptx.cmdline, logFile)
                def read_waytotal(waytotal):
                    f = open(waytotal, 'r')
                    w = f.readline()
                    f.close()
                    return w
                
                #if invert:
                #    op_str = '-add ' + os.path.join(tracts, 'tractsInv', 'fdt_paths.nii.gz')
                #    iFile = os.path.join(tracts, 'tracts', 'fdt_paths.nii.gz')
                #    oFile = os.path.join(tracts,'tracts', 'density.nii.gz')
                #    fslmaths = fsl.ImageMaths(in_file=iFile, op_string=op_str, out_file=oFile, output_type='NIFTI_GZ')
                #    fslmaths.run()
                #    write_log(fslmaths.cmdline, logFile)
                #    way1 = float(read_waytotal(os.path.join(tracts, 'tracts', 'waytotal')))
                #    way2 = float(read_waytotal(os.path.join(tracts, 'tractsInv', 'waytotal')))
                #    way = way1 + way2
                #else:
                #    iFile = os.path.join(tracts, 'tracts', 'fdt_paths.nii.gz')
                #    oFile = os.path.join(tracts,'tracts', 'density.nii.gz')
                #    fslmaths = fsl.ImageMaths(in_file=iFile, out_file=oFile, output_type='NIFTI_GZ')
                #    fslmaths.run()
                #    write_log(fslmaths.cmdline, logFile)
                #    way = float(read_waytotal(os.path.join(tracts, 'tracts', 'waytotal')))     
                way = float(read_waytotal(os.path.join(tracts, 'tracts', 'waytotal')))                  
                op_str = '-div ' + str(way) + ' -range'
                #iFile = os.path.join(tracts,'tracts', 'density.nii.gz')
                iFile = os.path.join(tracts,'tracts', 'fdt_paths.nii.gz')
                oFile = os.path.join(tracts,'tracts', 'tractsNorm.nii.gz')
                fslmaths = fsl.ImageMaths(in_file=iFile, op_string=op_str, out_file=oFile, output_type='NIFTI_GZ', out_data_type='float')
                fslmaths.run()
                write_log(fslmaths.cmdline, logFile)
    

    
class knicrTBSS():
    """
    knicrTBSS 
    
    A class of functions to run FSLs TBSS module in a stepwise fashion
    
    ...more to come...
    """
    def __init__(self, dtiDir, tbssDir, statsDir, template, **kwargs):
        #set some general paths to be used by all functions
        self.pfix = 'idc'
        self.dtiDir = dtiDir
        self.tbssDir = tbssDir
        self.faDir = os.path.join(self.tbssDir, 'FA')
        self.template = template
        if not os.path.exists(self.faDir):
            os.makedirs(self.faDir)
        self.statsDir = statsDir
        if self.tbssDir == self.statsDir:
            print 'Stats output folder CANNOT be the same as the TBSS dir...'
            print 'Please change the stats output folder...'
            sys.exit(0)
        if not os.path.exists(self.statsDir):
            os.makedirs(self.statsDir)
    
    def tbss_1_preproc(self, subject, **kwargs):
        """
        tbss_1_preproc
        
        An adaptation from FSLs tbss_1_preproc: $FSLDIR/bin/tbss_1_preproc
        
        !!!Changes from the FSL version!!!
        Some zero-padding is done in FSL, presumably to speed up the nonlinear registration. This is skipped here!
        """
        self.subject = subject
        fa = False
        tracula_format = False
        #check the optional arguments
        for i in kwargs.keys():
            if i == 'fa':
                if kwargs[i] == 'NLLS':
                    fa = os.path.join(self.dtiDir, subject, 'dmri', 'NLLS', 'dti_NLLS_fa.nii.gz')
                #because tracula seems to be doing some strange masking (with the aseg/wmparc)
                #we may need to compute the FA map again ourselves, with our own mask
                #this is because of the erosion step in tbss_1. 
                #The tracula brain_mask has some holes in the middle of the brain, where there are vessels.
                #this causes major problems with the erosion.  Further, the susceptibility artifact also causes masking problems for tbss.
                elif kwargs[i] == 'fsl':
                    fa = os.path.join(self.dtiDir, subject, 'dmri', 'fsl', 'dtifit_fsl_FA.nii.gz')
                elif kwargs[i] == 'knicr':
                    fa = os.path.join(self.dtiDir, subject, 'dmri', 'dtifit_FA.nii.gz')
                elif os.path.exists(kwargs[i]) and kwargs[i].endswith('.nii.gz'):
                    fa = kwargs[i]
            elif i == 'pfix':
                self.pfix = kwargs[i]
        #if you didn't specify any FA map, assume tracula format as default.
        if not fa:
            tracula_format=True
        #make sure you can even find a tracula fa map
        if tracula_format:
            fa = os.path.join(self.dtiDir, subject, 'dmri', 'dtifit_FA.nii.gz')
        #if not, exit out.
        if not os.path.exists(str(fa)):
            print 'Cannot locate FA map: '
            print 'dtiDir: ', self.dtiDir
            print 'Subject: ', subject
            print 'fa: ', fa
            return False
        #begin the tbss_1 preprocessing
        print 'Processing: ', subject
        #first we need to erode the FA map a bit, to get rid of the high signal voxels around the edges
        logFile = os.path.join(self.faDir, self.pfix + '_' + subject + '.tbss_1_preproc.log')
        self.fa = os.path.join(self.faDir, self.pfix + '_' + subject + '_FA.nii.gz')
        if not os.path.exists(self.fa):
            fslmaths = fsl.ImageMaths(in_file=fa, op_string='-ero -ero', out_file=self.fa, output_type='NIFTI_GZ', out_data_type='float')
            fslmaths.run()
            write_log(fslmaths.cmdline, logFile)
        #make a mask of the eroded file now
        #this actually is a boundary mask for FLIRT input weighting
        self.mask = self.fa.replace('.nii.gz', '_mask.nii.gz')
        if not os.path.exists(self.mask):
            fslmaths = fsl.ImageMaths(in_file=self.fa, op_string='-bin', out_file=self.mask, output_type='NIFTI_GZ', out_data_type='float')
            fslmaths.run()
            write_log(fslmaths.cmdline, logFile)
            op_str = '-dilD -dilD -sub 1 -abs -add ' + self.mask
            fslmaths = fsl.ImageMaths(in_file=self.mask, op_string=op_str, out_file=self.mask, output_type='NIFTI_GZ', out_data_type='char')
            fslmaths.run()
            write_log(fslmaths.cmdline, logFile)
        return True
    
    def tbss_2_reg(self):
        """
        tbss_2_reg
        
        Tool to run the flirt and fnirt steps of tbss.
        
        Note: we skip the computation of the mean deformation (i.e., _warp.msf, for determining the best fit from the all-to-all registration)
        
        This step must always follow the tbss_1_preproc....the fa map determined in step one is passed as self.fa.
        If tbss_1 has already been run once, and it's run again, it will not overwrite...
        """
        config='FA_2_FMRIB58_1mm'
        if not os.path.exists(self.fa):
            print 'Fa map not found: ', self.fa
            print 'run tbss_1_preproc first...'
            return
        obn = os.path.join(self.faDir, os.path.basename(self.fa).replace('.nii.gz', '') + '_to_' + os.path.basename(self.template).replace('.nii.gz', '') + '_lin')
        oFile = obn + '.nii.gz'
        mat = obn + '.mat'
        logFile = os.path.join(self.faDir, 'idc_' + self.subject + '.tbss_2_reg.log')
        if not os.path.exists(oFile):
            flirt = fsl.FLIRT(in_file=self.fa, reference=self.template, out_file=oFile, in_weight=self.mask, out_matrix_file=mat)
            flirt.run()
            write_log(flirt.cmdline, logFile)
        obn = os.path.join(self.faDir, os.path.basename(self.fa).replace('.nii.gz', '') + '_to_' + os.path.basename(self.template).replace('.nii.gz', '') + '_nonlin')
        self.warpedFile = obn + '.nii.gz'
        self.warp = obn + '_warp.nii.gz'
        log = obn + '_log.txt'
        if not os.path.exists(self.warp):
            fnirt = fsl.FNIRT(in_file=self.fa, fieldcoeff_file=self.warp, warped_file=self.warpedFile, affine_file=mat, config_file=config, ref_file=self.template, log_file=log)
            fnirt.run()
            write_log(fnirt.cmdline, logFile)
    
    def tbss_3_postregA(self):
        """
        tbss_3_postregA (A= only applywarp step)
        
        This simply does the applywarp step from tbss_3.
        This skips some main steps...namely the fsl merge and the skeletonization. Those are done in two subsequent steps...
        """
        if not os.path.exists(self.warp):
            print 'Cannot find warp file: ', self.warp
            return
        applywarp = fsl.ApplyWarp(in_file=self.fa, field_file=self.warp, out_file=self.warpedFile, ref_file=self.template, relwarp=True)
        applywarp.run()
        logFile = os.path.join(self.faDir, 'idc_' + self.subject + '.tbss_3_postreg.log')
        write_log(applywarp.cmdline, logFile)
    
    def tbss_3_postregB(self, subjList, **kwargs):
        self.threshold = 0.2 #pass a kwarg to change it?
        #first read in the subject list if it's not already in txt format.
        if not isinstance(subjList, list):
            txtopts = ('.csv', '.txt')
            if subjList.endswith(txtopts):
                subjList = read_txt(subjList)
        self.subjList = subjList
        mergeList = []
        #go through the subjlist and make a list of file names to append
        for subj in subjList:
            fa = os.path.join(os.path.join(self.faDir, self.pfix + '_' + subj + '_FA_to_' + os.path.basename(self.template).replace('.nii.gz', '') + '_nonlin.nii.gz'))
            if os.path.exists(fa):
                mergeList.append(fa)
            else:
                #error check....if the fa map isn't there...the whole show stops...
                print 'Subject: ', subj, '  Cannot locate FA MAP!!'
                print 'Cannot continue!!!'
                return False
        merged4d = os.path.join(self.statsDir, 'all_FA.nii.gz')
        print '4d: ', merged4d
        fslmerge = fsl.Merge(dimension='t', in_files=mergeList, merged_file=merged4d)
        fslmerge.run()
        logFile = os.path.join(self.statsDir, 'tbss_3_postregB.log')
        write_log(fslmerge.cmdline, logFile)
        subjinfo = os.path.join(self.statsDir, 'tbss_3_postreg_mergeInfo.csv')
        write_txt(subjList, subjinfo)
        #next we make the mean FA image
        op_str = '-max 0 -Tmin -bin'
        fslmaths = fsl.ImageMaths(in_file=merged4d, op_string=op_str, out_file=os.path.join(self.statsDir, 'mean_FA_mask.nii.gz'), output_type='NIFTI_GZ', out_data_type='char')
        fslmaths.run()
        write_log(fslmaths.cmdline, logFile)
        op_str = '-mas ' + os.path.join(self.statsDir, 'mean_FA_mask.nii.gz')
        fslmaths = fsl.ImageMaths(in_file=merged4d, op_string=op_str, out_file=merged4d, output_type='NIFTI_GZ')
        fslmaths.run()
        write_log(fslmaths.cmdline, logFile)
        op_str = '-Tmean'
        fslmaths = fsl.ImageMaths(in_file=merged4d, op_string=op_str, out_file=os.path.join(self.statsDir, 'mean_FA.nii.gz'), output_type='NIFTI_GZ')
        fslmaths.run()
        write_log(fslmaths.cmdline, logFile)
        #now make the initial skeleton
        tbss_skeleton = fsl.TractSkeleton(in_file=os.path.join(self.statsDir, 'mean_FA.nii.gz'), skeleton_file=os.path.join(self.statsDir, 'mean_FA_skeleton.nii.gz'))
        tbss_skeleton.run()
        write_log(tbss_skeleton.cmdline, logFile)
        self.merged4d = merged4d
        return True
    
    def tbss_4_prestats(self, **kwargs):
        threshold = 0.2 #use a kwarg to edit this?
        logFile = os.path.join(self.statsDir, 'tbss_4_prestats.log')
        print 'Creating Skeleton Mask using threshold', str(threshold)
        op_str = '-thr ' + str(threshold) + ' -bin'
        fslmaths = fsl.ImageMaths(in_file=os.path.join(self.statsDir, 'mean_FA_skeleton.nii.gz'), op_string=op_str, out_file=os.path.join(self.statsDir, 'mean_FA_skeleton_mask.nii.gz'), output_type='NIFTI_GZ')
        fslmaths.run()
        write_log(fslmaths.cmdline, logFile)
        print 'Creating skeleton distancemap (for use in projection search)'
        op_str = '-mul 1 -add 1 -add ' + os.path.join(self.statsDir, 'mean_FA_skeleton_mask.nii.gz')
        fslmaths = fsl.ImageMaths(in_file=os.path.join(self.statsDir, 'mean_FA_mask.nii.gz'), op_string=op_str, out_file=os.path.join(self.statsDir, 'mean_FA_skeleton_mask_dst.nii.gz'), output_type='NIFTI_GZ')
        fslmaths.run()
        write_log(fslmaths.cmdline, logFile)
        distancemap = fsl.DistanceMap(in_file=os.path.join(self.statsDir, 'mean_FA_skeleton_mask_dst.nii.gz'), distance_map=os.path.join(self.statsDir, 'mean_FA_skeleton_mask_dst.nii.gz'))
        distancemap.run()
        write_log(distancemap.cmdline, logFile)
        #do a quick check on the cingulum file...make sure it's the right size!
        nb_template = nb.load(self.template)
        x = abs(nb_template.get_affine()[0][0])
        y = abs(nb_template.get_affine()[1][1])
        z = abs(nb_template.get_affine()[2][2])
        cing_file1mm = os.path.join(os.environ['FSLDIR'], 'data', 'standard', 'LowerCingulum_1mm.nii.gz')
        if x == 1 and y == 1 and z == 1:
            cing_file = cing_file1mm
        elif x == 2 and y == 2 and z == 2:
            cing_file = os.path.join(os.environ['FSLDIR'], 'data', 'standard', 'LowerCingulum_2mm.nii.gz')
            if not os.path.exists(cing_file):
                cing_file = os.path.join(self.statsDir, 'LowerCingulum_2mm.nii.gz')
                flirt = fsl.FLIRT(in_file=cing_file1mm, reference=os.path.join(os.environ['FSLDIR'], 'data', 'standard', 'MNI152_T1_2mm.nii.gz'), out_file=cing_file, args='-applyisoxfm 2')
                flirt.run()
                write_log(flirt.cmdline, logFile)
        print 'Projecting all FA data onto Skeleton'
        final4d = self.merged4d.replace('.nii.gz', '_skeletonized.nii.gz')
        tbss_skeleton = fsl.TractSkeleton(threshold=threshold, distance_map=os.path.join(self.statsDir, 'mean_FA_skeleton_mask_dst.nii.gz'), 
        data_file=self.merged4d, projected_data=final4d, in_file=os.path.join(self.statsDir, 'mean_FA.nii.gz'), project_data=True)
        tbss_skeleton.inputs.use_cingulum_mask = Undefined
        tbss_skeleton.inputs.search_mask_file=cing_file
        tbss_skeleton.run()
        write_log(tbss_skeleton.cmdline, logFile)
    
    def tbss_nonFA_reg(self, subject, nonFA):
        iFile = os.path.join(self.dtiDir, subject, 'dmri', nonFA + '.nii.gz')
        #do the reg for each subject here
        warp = os.path.join(self.faDir, self.pfix + '_' + subject + '_FA_to_' + os.path.basename(self.template).replace('.nii.gz', '') + '_nonlin_warp.nii.gz')
        if not os.path.exists(warp):
            print 'Cannot find warp file: ', warp
            sys.exit(0)
            return False
        oFile = os.path.join(self.faDir, self.pfix + '_' + subject + '_' + nonFA + '_to_' + os.path.basename(self.template).replace('.nii.gz', '') + '_nonlin.nii.gz')
        if not os.path.exists(oFile):
            applywarp = fsl.ApplyWarp(in_file=iFile, field_file=warp, out_file=oFile, ref_file=self.template, relwarp=True)
            applywarp.run()
            logFile = os.path.join(self.faDir, 'idc_' + self.subject + '.tbss_nonFA.log')
            write_log(applywarp.cmdline, logFile)
    
    def tbss_nonFA_merge(self, nonFA, subjList):
        threshold=0.2
        #first read in the subject list if it's not already in txt format.
        if not isinstance(subjList, list):
            txtopts = ('.csv', '.txt')
            if subjList.endswith(txtopts):
                subjList = read_txt(subjList)
        self.subjList = subjList
        mergeList = []
        #go through the subjlist and make a list of file names to append
        for subj in subjList:
            scalar = os.path.join(self.faDir, self.pfix + '_' + subj + '_' + nonFA + '_to_' + os.path.basename(self.template).replace('.nii.gz', '') + '_nonlin.nii.gz')
            if os.path.exists(scalar):
                mergeList.append(scalar)
            else:
                #error check....if the fa map isn't there...the whole show stops...
                print 'Subject: ', subj, '  Cannot locate FA MAP!!'
                print 'Cannot continue!!!'
                return False
        merged4d = os.path.join(self.statsDir, 'all_' + nonFA + '.nii.gz')
        print '4d: ', merged4d
        #mer
        fslmerge = fsl.Merge(dimension='t', in_files=mergeList, merged_file=merged4d)
        fslmerge.run()
        logFile = os.path.join(self.statsDir, 'tbss_nonFA.log')
        write_log(fslmerge.cmdline, logFile)
        subjinfo = os.path.join(self.statsDir, 'tbss_nonFA_' + nonFA + '_mergeInfo.csv')
        write_txt(subjList, subjinfo)
        #mask it
        op_str = '-mas ' + os.path.join(self.statsDir, 'mean_FA_mask.nii.gz')
        fslmaths = fsl.ImageMaths(in_file=merged4d, op_string=op_str, out_file=merged4d, output_type='NIFTI_GZ')
        fslmaths.run()
        logFile = os.path.join(self.statsDir, 'tbss_nonFA.log')
        write_log(fslmaths.cmdline, logFile)
        #skeletenize
        nb_template = nb.load(self.template)
        x = abs(nb_template.get_affine()[0][0])
        y = abs(nb_template.get_affine()[1][1])
        z = abs(nb_template.get_affine()[2][2])
        cing_file1mm = os.path.join(os.environ['FSLDIR'], 'data', 'standard', 'LowerCingulum_1mm.nii.gz')
        if x == 1 and y == 1 and z == 1:
            cing_file = cing_file1mm
        elif x == 2 and y == 2 and z == 2:
            cing_file = os.path.join(os.environ['FSLDIR'], 'data', 'standard', 'LowerCingulum_2mm.nii.gz')
            if not os.path.exists(cing_file):
                cing_file = os.path.join(self.statsDir, 'LowerCingulum_2mm.nii.gz')
                flirt = fsl.FLIRT(in_file=cing_file1mm, reference=os.path.join(os.environ['FSLDIR'], 'data', 'standard', 'MNI152_T1_2mm.nii.gz'), out_file=cing_file, args='-applyisoxfm 2')
                flirt.run()
                write_log(flirt.cmdline, logFile)
        else:
            cing_file=False
        if not cing_file:
            print 'Cannot find cingulum file.'
            return
        print 'Projecting all FA data onto Skeleton'
        final4d = merged4d.replace('.nii.gz', '_skeletonized.nii.gz')
        #run the tbss skeletonize thing
        tbss_skeleton = fsl.TractSkeleton(threshold=threshold, distance_map=os.path.join(self.statsDir, 'mean_FA_skeleton_mask_dst.nii.gz'), alt_data_file=merged4d, 
        data_file=os.path.join(self.statsDir, 'all_FA.nii.gz'), projected_data=final4d, in_file=os.path.join(self.statsDir, 'mean_FA.nii.gz'), project_data=True)
        tbss_skeleton.inputs.use_cingulum_mask = Undefined
        tbss_skeleton.inputs.search_mask_file=cing_file
        tbss_skeleton.run()
        write_log(tbss_skeleton.cmdline, logFile)
    









class knicrDTIFIT():
    """
    kncirDTIFIT
    
    A class to fit the diffusion tensor using FSLs dti fit package
    
    ... more to come ...
    """
    def __init__(self, dtiDir):
        self.dtiDir = dtiDir
    
    def FSLdtifit(self, subject, **kwargs):
        tracula_format = True
        if not tracula_format:
            return
        #set the output base name
        self.obn = os.path.join(self.dtiDir, subject, 'dmri', 'fsl', 'dtifit_fsl')
        #specify the gradient table
        bvecs = os.path.join(self.dtiDir, subject, 'dmri', 'bvecs')
        #specify the bvalues
        bvals = os.path.join(self.dtiDir, subject, 'dmri', 'bvals')
        #give the dwi input file
        iFile = os.path.join(self.dtiDir, subject, 'dmri', 'data.nii.gz')
        #specify the brain mask
        mask = os.path.join(self.dtiDir, subject, 'dmri', 'fsl', 'nodif_brain_mask.nii.gz')
        #in case the brain mask doesn't exist, specify the output for BET
        nodif_brain = os.path.join(self.dtiDir, subject, 'dmri', 'fsl', 'nodif_brain.nii.gz')
        if not os.path.exists(os.path.dirname(self.obn)):
            #make the output folder
            os.makedirs(os.path.dirname(self.obn))
        #if the brain mask doesn't exist...make it with bet
        if not os.path.exists(mask):
            bet = fsl.BET(frac=0.25, in_file=iFile, mask=True, out_file=nodif_brain)
            bet.run()
            logFile = os.path.join(os.path.dirname(mask), 'bet.log')
            write_log(bet.cmdline, logFile)
        #if the FA map doesn't exist....compute the tensor
        if not os.path.exists(self.obn + '_FA.nii.gz'):
            #in the current version of nipype...it doesn't handle the out_files properly, in terms of finding them
            #thus, the ignore_exception flag is activated..
            fit = fsl.DTIFit(base_name=self.obn, bvals=bvals, bvecs=bvecs, dwi=iFile, mask=mask, terminal_output='stream', ignore_exception=True)
            fit.run()
            logFile = self.obn + '.log'
            write_log(fit.cmdline, logFile)
    
    def compute_scalars(self):
        #first make the axial diffusion scan...a simple copy of the primary eigen value
        iFile = self.obn + '_L1.nii.gz'
        oFile = self.obn + '_AD.nii.gz'
        fslmaths = fsl.ImageMaths(in_file=iFile, out_file=oFile, output_type='NIFTI_GZ', out_data_type='float')
        fslmaths.run()
        logFile = self.obn + '.log'
        write_log(fslmaths.cmdline, logFile)
        #next make the radial diffusivity scan...an average of the secondary and tertiary eigenvalues
        iFile = self.obn + '_L2.nii.gz'
        rd_op_str = '-add ' + self.obn + '_L3.nii.gz' + ' -div 2'
        oFile = self.obn + '_RD.nii.gz'
        fslmaths = fsl.ImageMaths(in_file=iFile, op_string=rd_op_str, out_file=oFile, output_type='NIFTI_GZ', out_data_type='float')
        fslmaths.run()
        logFile = self.obn + '.log'
        write_log(fslmaths.cmdline, logFile)
    

